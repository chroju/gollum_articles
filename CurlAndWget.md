比較
----

* [wgetとcurlの根本的な違い - ctrlshiftの日記](http://d.hatena.ne.jp/ctrlshift/20080129/1201612626)
* [curlとWgetの比較 | インフラ・ミドルウェア | POSTD](http://postd.cc/curl-vs-wget/)

後者の記事のブコメから。

> wgetの用途は再帰的取得を活かしたクローリング。擬似ブラウザ。curlは1URLに対してどれだけのアプローチ方法が取れるかというところなので目的が全然違う

一方でCurlは連番指定でのアクセスが可能という点がある。基本的に単発URLへのアクセス手段（多数のプロトコル対応など）に優れたCurlと、ウェブブラウザチックなクロールを可能とするWgetという差になりそう。またオプションなしの挙動だとWgetがダウンロードを伴う一方、Curlは伴わず標準出力へパイプするため、単純なアクセスのみ（例えばAPIへのアクセス）であればCurlを使う方が楽。


各コマンドの使用法
----

### curl

* `-s` : サイレントモード。
* `-S` : `-s`と併用するとエラーだけは出力してくれる。
* `-v` : 詳細表示。
* `-L, --location` : 3xx Redirectionが返ってきた場合に自動的にリダイレクトを行う。
* `-D, --dump-header <file>` : fileにレスポンスヘッダーを出力する。標準出力にすることも可。
* `-H, --header` : リクエストヘッダーを指定。複数ある場合は1つずつ。
* `--data-urlencode` : クエリをエンコードしてくれる。エンコードしないものは`--data`。
* `-d, --data` : 上述の通りクエリ。`-d @json`とするとファイル名jsonのファイルを読み込む。jsonの場合はこちらの方が楽。
* `-O` : 出力をローカル保存する。ファイル名はURLから自動指定される。`-o`でファイル名指定での保存ができる。

### wget

* `-O` : 出力先の指定。ファイル名、もしくは`-`で標準出力にすることも可能。

参考
----

[WebAPIリクエスト仕様書としてcurlコマンドのご提案 - Qiita](http://qiita.com/Hiraku/items/dfda2f8a5353b0742271)
